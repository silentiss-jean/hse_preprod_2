# -*- coding: utf-8 -*-

"""Plateforme sensor pour Home Suivi Ã‰lec â€” Phase 3.0."""

import logging

from typing import Iterable, List, Optional, Set, Tuple

from homeassistant.core import HomeAssistant, callback

from homeassistant.config_entries import ConfigEntry

from homeassistant.helpers.entity_platform import AddEntitiesCallback

from homeassistant.helpers import entity_registry as er

from .const import DOMAIN

LOGGER = logging.getLogger(__name__)
LOGGER.error("HSE SENSOR.PY IMPORTED (debug marker)")

def _uid(ent) -> Optional[str]:
    # HA Entities exposent gÃ©nÃ©ralement unique_id (property) + stockage interne _attr_unique_id
    return getattr(ent, "unique_id", None) or getattr(ent, "_attr_unique_id", None)

def _get_added_uids(hass: HomeAssistant) -> Set[str]:
    domain_data = hass.data.setdefault(DOMAIN, {})
    return domain_data.setdefault("_added_uids", set())

# ======================================================================
# âš™ï¸ DÃ‰DUP HSE : CONFIG MODIFIÃ‰E
# 
# - PAS de seed depuis l'entity_registry au dÃ©marrage (MODIFIÃ‰)
# - DÃ©dup dÃ©sactivÃ©e pour permettre rÃ©gÃ©nÃ©ration (MODIFIÃ‰)
# - Les capteurs existants dans le registry sont rÃ©animÃ©s (NOUVEAU)
# ======================================================================
# Anciennement :
# - MODE DEV : pas de seed, pas de dÃ©dup (tous les sensors recrÃ©Ã©s Ã  chaque reboot)
# - MODE PROD : seed registry + dÃ©dup stricte par unique_id
# 
# La config actuelle Ã©quivaut Ã  :
# - PAS de seed registry (pour permettre rÃ©gÃ©nÃ©ration)
# - DÃ©dup dÃ©sactivÃ©e pour tous les types de capteurs

def _seed_added_uids_from_registry(hass: HomeAssistant) -> None:
    """
    Seed du set runtime avec les entitÃ©s dÃ©jÃ  prÃ©sentes.
    
    âš ï¸ DÃ‰SACTIVÃ‰ dans async_setup_entry pour permettre la rÃ©gÃ©nÃ©ration.
    """
    added = _get_added_uids(hass)
    added.clear()
    
    ent_reg = er.async_get(hass)
    for entry in ent_reg.entities.values():
        if entry.domain != "sensor":
            continue
        if entry.platform != DOMAIN:
            continue
        if entry.unique_id:
            added.add(entry.unique_id)
    
    LOGGER.info("ğŸ§¯ [DEDUP] seed: %s unique_id dÃ©jÃ  prÃ©sents", len(added))

def _dedupe_by_uid(
    hass: HomeAssistant, sensors: Iterable, kind: str
) -> Tuple[List, Set[str], int]:
    """
    Filtre les entitÃ©s dÃ©jÃ  ajoutÃ©es (par unique_id).
    
    MODIFIÃ‰: DÃ©dup dÃ©sactivÃ©e pour permettre rÃ©gÃ©nÃ©ration aprÃ¨s redÃ©marrage.
    """
    added = _get_added_uids(hass)
    
    out: List = []
    new_uids: Set[str] = set()
    skipped = 0
    missing_uid = 0
    
    for e in list(sensors or []):
        uid = _uid(e)
        if not uid:
            # Pas de dÃ©dup possible => on laisse passer, mais on log
            missing_uid += 1
            out.append(e)
            continue
        
        # ğŸ”§ MODIFICATION CRITIQUE: DÃ©dup dÃ©sactivÃ©e pour tous les types
        if uid in added:
            LOGGER.debug(
                "ğŸ”„ [DEDUP] %s: entitÃ© %s existe dans registry, rÃ©animation autorisÃ©e",
                kind,
                uid
            )
            # NE PAS skip - on laisse passer pour rÃ©gÃ©nÃ©ration
        
        out.append(e)
        new_uids.add(uid)
    
    if skipped:
        LOGGER.info("ğŸ§¯ [DEDUP] %s: %s entitÃ©s dÃ©jÃ  ajoutÃ©es ignorÃ©es", kind, skipped)
    if missing_uid:
        LOGGER.warning(
            "ğŸ§¯ [DEDUP] %s: %s entitÃ©s sans unique_id (pas de dÃ©dup)",
            kind,
            missing_uid,
        )
    
    return out, new_uids, skipped

async def _reconcile_cost_sensors(hass: HomeAssistant) -> list:
    """
    RecrÃ©e les capteurs coÃ»t persistÃ©s au dÃ©marrage (rÃ©conciliation).
    AppelÃ© au setup pour garantir que les capteurs coÃ»t existent toujours.
    """
    try:
        mgr = hass.data.get(DOMAIN, {}).get("storage_manager")
        if not mgr:
            LOGGER.warning("[COST-RECONCILE] StorageManager non disponible, skip")
            return []
        
        user_cfg = await mgr.get_user_config()
        if not user_cfg.get("enable_cost_sensors_runtime"):
            LOGGER.info("[COST-RECONCILE] Runtime dÃ©sactivÃ©, skip")
            return []
        
        cost_ha_map = await mgr.get_cost_ha_config()
        if not cost_ha_map:
            LOGGER.info("[COST-RECONCILE] Aucun capteur coÃ»t persistÃ©")
            return []
        
        # Filtrer uniquement ceux enabled=True
        enabled_sources = {
            entity_id: cfg
            for entity_id, cfg in cost_ha_map.items()
            if isinstance(cfg, dict) and cfg.get("enabled")
        }
        
        if not enabled_sources:
            LOGGER.info("[COST-RECONCILE] Aucun capteur coÃ»t enabled")
            return []
        
        LOGGER.info("[COST-RECONCILE] %d sources Ã  rÃ©concilier", len(enabled_sources))
        
        # Lire pricing actuel (peut avoir changÃ© depuis la gÃ©nÃ©ration)
        from .cost_tracking import get_pricing_config
        pricing = get_pricing_config(hass)
        current_type = pricing.get("type_contrat", "fixe")
        
        # DÃ©tecter changement de contrat
        needs_migration = False
        for entity_id, cfg in enabled_sources.items():
            stored_type = cfg.get("type_contrat", "fixe")
            if stored_type != current_type:
                LOGGER.warning(
                    "[COST-RECONCILE] Type contrat changÃ© (%s â†’ %s) pour %s",
                    stored_type, current_type, entity_id
                )
                needs_migration = True
                break
        
        if needs_migration:
            LOGGER.warning(
                "[COST-RECONCILE] Migration nÃ©cessaire (changement contrat), "
                "veuillez rÃ©gÃ©nÃ©rer manuellement les capteurs coÃ»t"
            )
            return []
        
        # RÃ©gÃ©nÃ©rer les capteurs coÃ»t depuis le store
        from .cost_tracking import create_cost_sensors
        
        cost_sensors = await create_cost_sensors(
            hass,
            prix_ht=pricing.get("prix_ht"),
            prix_ttc=pricing.get("prix_ttc"),
            allowed_source_entity_ids=set(enabled_sources.keys())
        )
        
        if cost_sensors:
            LOGGER.info("[COST-RECONCILE] âœ… %d capteurs coÃ»t rÃ©conciliÃ©s", len(cost_sensors))
        else:
            LOGGER.info("[COST-RECONCILE] Aucun capteur coÃ»t crÃ©Ã© (allowlist vide?)")
        
        return cost_sensors or []
    
    except Exception as e:
        LOGGER.exception("[COST-RECONCILE] Erreur lors de la rÃ©conciliation: %s", e)
        return []


def _take_pool(hass: HomeAssistant, pending_key: str, stable_key: str) -> list:
    """
    RÃ©cupÃ¨re la liste Ã  ajouter.
    
    - PrioritÃ© au pending (pop => consommÃ© une fois)
    - Fallback sur stable (get), mais dÃ©dupliquÃ© ensuite
    """
    domain_data = hass.data.setdefault(DOMAIN, {})
    sensors = domain_data.pop(pending_key, None)
    if sensors is None:
        sensors = domain_data.get(stable_key, []) or []
    return sensors

# NOTE: Cette fonction _process() globale n'est JAMAIS utilisÃ©e car elle est
# redÃ©finie Ã  l'intÃ©rieur de async_setup_entry(). Elle est conservÃ©e pour
# rÃ©fÃ©rence mais pourrait Ãªtre supprimÃ©e.
def _process(kind: str, pending_key: str, stable_key: str) -> None:
    """Version globale NON UTILISÃ‰E - voir version dans async_setup_entry()."""
    # Cette fonction ne peut pas fonctionner ici car hass et async_add_entities
    # ne sont pas accessibles Ã  ce niveau
    pass

async def async_setup_entry(
    hass: HomeAssistant,
    entry: ConfigEntry,
    async_add_entities: AddEntitiesCallback,
) -> None:
    """Set up sensors from a config entry â€” EVENT-DRIVEN."""
    LOGGER.info("ğŸ¯ [EVENT-DRIVEN] Setup sensor platform - Attente events...")
    
    # ğŸ”§ MODIFICATION CRITIQUE: Ne plus seed depuis le registry
    # _seed_added_uids_from_registry(hass)  # DÃ‰SACTIVÃ‰
    
    # Ã€ la place, on vide le set pour permettre rÃ©gÃ©nÃ©ration complÃ¨te
    _get_added_uids(hass).clear()
    LOGGER.info("ğŸ§¯ [DEDUP] Set runtime vidÃ© pour rÃ©gÃ©nÃ©ration complÃ¨te")
    
    EVENT_TO_KEYS = {
        "hse_energy_sensors_ready": ("energy_sensors_pending", "energy_sensors", "energy"),
        "hse_power_sensors_ready": ("live_power_sensors_pending", "live_power_sensors", "power"),
        "hse_power_energy_sensors_ready": ("power_energy_sensors_pending", "power_energy_sensors", "power_energy"),
        "hse_cost_sensors_ready": ("cost_sensors_pending", "cost_sensors", "cost"),
    }
    
    def _process(kind: str, pending_key: str, stable_key: str) -> None:
        sensors = _take_pool(hass, pending_key, stable_key)
        
        # --- DEBUG: Ã©tat brut avant dÃ©dup
        raw_count = len(list(sensors or []))
        raw_uids = []
        raw_names = []
        for e in list(sensors or [])[:8]:
            raw_uids.append(_uid(e))
            raw_names.append(getattr(e, "name", None) or getattr(e, "_attr_name", None))
        
        LOGGER.info(
            "ğŸ§© [EVENT-RAW] %s: pool=%s/%s raw_count=%s sample_uids=%s sample_names=%s",
            kind,
            pending_key,
            stable_key,
            raw_count,
            raw_uids,
            raw_names,
        )
        
        sensors, new_uids, skipped = _dedupe_by_uid(hass, sensors, kind)
        
        # --- DEBUG: rÃ©sultat aprÃ¨s dÃ©dup
        LOGGER.info(
            "ğŸ§© [EVENT-DEDUP] %s: kept=%s skipped=%s new_uids=%s",
            kind,
            len(sensors or []),
            skipped,
            list(new_uids)[:10],
        )
        
        if not sensors:
            LOGGER.warning("âš ï¸ [EVENT] %s: aucun sensor Ã  ajouter (pool vide ou tout filtrÃ©)", kind)
            return
        
        # Ajout HA
        try:
            async_add_entities(sensors, True)
            
            # Marquer ajoutÃ© aprÃ¨s l'appel (Ã©vite de "brÃ»ler" des UID si une exception arrive avant)
            _get_added_uids(hass).update(new_uids)
            LOGGER.info("âœ… [EVENT-PROCESSED] %s: %s sensors ajoutÃ©s", kind, len(sensors))
        except Exception as e:
            LOGGER.exception("âŒ [EVENT-ERROR] Ã‰chec ajout sensors %s: %s", kind, e)
    
    @callback
    def on_hse_sensors_ready(event):
        try:
            info = EVENT_TO_KEYS.get(event.event_type)
            if not info:
                LOGGER.warning("âš ï¸ [EVENT] event inconnu: %s", event.event_type)
                return
            
            pending_key, stable_key, kind = info
            LOGGER.info("ğŸ“£ [EVENT] RÃ©ception event: %s", event.event_type)
            _process(kind, pending_key, stable_key)
        except Exception as e:
            LOGGER.exception("âŒ [EVENT-ERROR] %s", e)
    
    # --- nouveau: listeners BUS (pas dispatcher) ---
    def _extract_pending(pool_key: str):
        domain_data = hass.data.get(DOMAIN, {})
        pending = domain_data.get(pool_key) or []
        # IMPORTANT: on vide le pool pour Ã©viter les doublons au prochain event
        domain_data[pool_key] = []
        return pending

    async def _on_room_totals_ready(event):
        pending = _extract_pending("room_totals_sensors_pending")
        if not pending:
            _LOGGER.warning("ROOM-TOTALS aucun sensor Ã  ajouter (pool vide)")
            return
        async_add_entities(pending, True)

    async def _on_type_totals_ready(event):
        pending = _extract_pending("type_totals_sensors_pending")
        if not pending:
            _LOGGER.warning("TYPE-TOTALS aucun sensor Ã  ajouter (pool vide)")
            return
        async_add_entities(pending, True)

    unsub_room = hass.bus.async_listen("hse_room_totals_ready", _on_room_totals_ready)
    unsub_type = hass.bus.async_listen("hse_type_totals_ready", _on_type_totals_ready)

    # stocke les unsub pour pouvoir clean Ã  unload
    hass.data.setdefault(DOMAIN, {}).setdefault("_unsub_listeners", []).extend([unsub_room, unsub_type])

    # listeners
    for ev in EVENT_TO_KEYS.keys():
        hass.bus.async_listen(ev, on_hse_sensors_ready)
    
    LOGGER.info("ğŸ§ [EVENT-DRIVEN] Listeners activÃ©s - En attente des events sensors...")
    
    # backup flush (startup): on tente d'ajouter ce qui est dÃ©jÃ  prÃªt
    LOGGER.info("ğŸ”„ [STARTUP] Tentative flush des pools existants...")
    for _ev, (pending_key, stable_key, kind) in EVENT_TO_KEYS.items():
        _process(kind, pending_key, stable_key)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”„ RÃ‰CONCILIATION : Capteurs coÃ»t persistÃ©s
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LOGGER.info("ğŸ”„ [COST-RECONCILE] RÃ©conciliation des capteurs coÃ»t...")
    
    try:
        cost_sensors = await _reconcile_cost_sensors(hass)
        
        if cost_sensors:
            # Appliquer dÃ©dup standard
            cost_sensors, new_uids, skipped = _dedupe_by_uid(hass, cost_sensors, "cost_reconcile")
            
            if cost_sensors:
                async_add_entities(cost_sensors, update_before_add=True)
                _get_added_uids(hass).update(new_uids)
                LOGGER.info(
                    "âœ… [COST-RECONCILE] %d capteurs coÃ»t ajoutÃ©s (%d dÃ©dupliquÃ©s)",
                    len(cost_sensors),
                    skipped
                )
            else:
                LOGGER.info("[COST-RECONCILE] Tous les capteurs coÃ»t Ã©taient dÃ©jÃ  prÃ©sents")
        else:
            LOGGER.info("[COST-RECONCILE] Aucun capteur coÃ»t Ã  rÃ©concilier")
    
    except Exception as e:
        LOGGER.exception("[COST-RECONCILE] Erreur lors de la rÃ©conciliation: %s", e)